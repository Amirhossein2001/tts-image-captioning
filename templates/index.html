<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Image Caption + OCR + TTS</title>
  <style>
    .gallery, .text-section {
      display: flex;
      flex-direction: column;
      align-items: center;
      margin-top: 20px;
    }
    .image-container, .text-container {
      position: relative;
      margin: 20px;
      text-align: center;
      padding: 10px;
      border: 1px solid #ccc;
      border-radius: 8px;
      background: #f9f9f9;
      width: 300px;
    }
    .caption {
      font-size: 16px;
      font-weight: bold;
      color: white;
      background: rgba(0, 0, 0, 0.7);
      padding: 5px 10px;
      border-radius: 5px;
      position: absolute;
      bottom: 5px;
      left: 50%;
      transform: translateX(-50%);
      width: 90%;
      text-align: center;
    }
    .hover-text {
      font-size: 18px;
      font-weight: bold;
      cursor: pointer;
      padding: 5px;
      background: lightblue;
      border-radius: 5px;
      margin: 10px;
      width: 250px;
      text-align: center;
    }
  </style>
</head>
<body>
  <h1>Hover over an image or text to generate captions and listen</h1>

  <!-- ØªØµØ§ÙˆÛŒØ± -->
  <div class="gallery">
    <div class="image-container" onmouseover="getCaption(this)">
      <img src="https://www.visualwatermark.com/images/add-text-to-photos/add-text-to-photo-4.webp" alt="Sample Image" width="300">
      <div class="caption">Caption will appear here</div>
    </div>
  </div>

  <!-- Ù…ØªÙ†â€ŒÙ‡Ø§ÛŒ Ù‚Ø§Ø¨Ù„ ØªØ¨Ø¯ÛŒÙ„ Ø¨Ù‡ ØµÙˆØª -->
  <div class="text-section">
    <div class="text-container" onmouseover="convertTextToSpeech(this)">
      <p class="hover-text">This is the first text to convert.</p>
    </div>
    <div class="text-container" onmouseover="convertTextToSpeech(this)">
      <p class="hover-text">Another example text to speak.</p>
    </div>
    <div class="text-container" onmouseover="convertTextToSpeech(this)">
      <p class="hover-text">Hover over me to hear my voice.</p>
    </div>
  </div>

  <!-- Ø¹Ù†ØµØ± ØµÙˆØªÛŒ Ù…Ø®ÙÛŒ Ø¨Ø§ preload Ø¨Ø±Ø§ÛŒ Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø¯Ø§Ù†Ù„ÙˆØ¯ -->
  <audio id="audioPlayer" preload="auto" style="display:none;"></audio>

  <script>
    function getCaption(imageContainer) {
      const img = imageContainer.querySelector("img");
      const captionDiv = imageContainer.querySelector(".caption");
      const audioPlayer = document.getElementById("audioPlayer");

      if (!img || !captionDiv) return;

      // Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ
      if (imageContainer.dataset.fetching === "true") {
        console.log("âš ï¸ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¬Ø±Ø§ Ø§Ø³ØªØŒ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¬Ø¯ÛŒØ¯ Ø§Ø±Ø³Ø§Ù„ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯.");
        return;
      }

      imageContainer.dataset.fetching = "true";

      console.log("ðŸ“Œ Ø§Ø±Ø³Ø§Ù„ Ø¯Ø±Ø®ÙˆØ§Ø³Øª GET Ø¨Ø±Ø§ÛŒ:", img.src);

      fetch(`/caption?image_url=${encodeURIComponent(img.src)}`)
        .then(response => response.json())
        .then(data => {
          console.log("ðŸ“Œ Ù¾Ø§Ø³Ø® Ø³Ø±ÙˆØ±:", data);

          if (!data.caption || !data.ocr_text) {
            captionDiv.textContent = "Error fetching caption or OCR!";
            console.error("âŒ Ø®Ø·Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØª Ú©Ù¾Ø´Ù† ÛŒØ§ OCR:", data);
            return;
          }

          captionDiv.textContent = `ðŸ“¸ ${data.caption}\nðŸ“– ${data.ocr_text}`;

          if (data.audio_url && data.audio_url !== "undefined" && data.audio_url !== null) {
            console.log("ðŸ“Œ Ù¾Ø®Ø´ ØµÙˆØª:", data.audio_url);
            audioPlayer.src = data.audio_url;
            audioPlayer.load();
            audioPlayer.play();
          } else {
            console.warn("âš ï¸ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.");
          }
        })
        .catch(error => console.error('âŒ Fetch error:', error))
        .finally(() => {
          imageContainer.dataset.fetching = "false";
        });
    }

    function convertTextToSpeech(textContainer) {
      const text = textContainer.querySelector(".hover-text").textContent;
      const audioPlayer = document.getElementById("audioPlayer");

      if (!text) return;

      // Ø¬Ù„ÙˆÚ¯ÛŒØ±ÛŒ Ø§Ø² Ø¯Ø±Ø®ÙˆØ§Ø³Øªâ€ŒÙ‡Ø§ÛŒ ØªÚ©Ø±Ø§Ø±ÛŒ
      if (textContainer.dataset.fetching === "true") {
        console.log("âš ï¸ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¯Ø± Ø­Ø§Ù„ Ø§Ø¬Ø±Ø§ Ø§Ø³ØªØŒ Ø¯Ø±Ø®ÙˆØ§Ø³Øª Ø¬Ø¯ÛŒØ¯ Ø§Ø±Ø³Ø§Ù„ Ù†Ù…ÛŒâ€ŒØ´ÙˆØ¯.");
        return;
      }

      textContainer.dataset.fetching = "true";

      console.log("ðŸ“Œ Ø§Ø±Ø³Ø§Ù„ Ø¯Ø±Ø®ÙˆØ§Ø³Øª TTS Ø¨Ø±Ø§ÛŒ Ù…ØªÙ†:", text);

      fetch(`/tts?text=${encodeURIComponent(text)}`)
        .then(response => response.json())
        .then(data => {
          console.log("ðŸ“Œ Ù¾Ø§Ø³Ø® Ø³Ø±ÙˆØ± Ø¨Ø±Ø§ÛŒ TTS:", data);

          if (data.audio_url && data.audio_url !== "undefined" && data.audio_url !== null) {
            console.log("ðŸ“Œ Ù¾Ø®Ø´ ØµÙˆØª:", data.audio_url);
            audioPlayer.src = data.audio_url;
            audioPlayer.load();
            audioPlayer.play();
          } else {
            console.warn("âš ï¸ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ ÛŒØ§ÙØª Ù†Ø´Ø¯.");
          }
        })
        .catch(error => console.error('âŒ Fetch error:', error))
        .finally(() => {
          textContainer.dataset.fetching = "false";
        });
    }
  </script>
</body>
</html>
